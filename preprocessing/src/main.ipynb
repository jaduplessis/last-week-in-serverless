{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for example content...\n",
      "Generating embeddings for:   AWS Glue now can detect 250 sensitive entity types from over 50 countries \n",
      "Generating embeddings for:   AWS Step Functions launches Versions and Aliases \n",
      "Generating embeddings for:   Announcing the AWS Amplify UI Builder Figma plugin \n",
      "Generating embeddings for:   AWS Lambda supports starting from timestamp for Kafka event sources \n",
      "Generating embeddings for:   Amazon CloudWatch Logs announces new Log Insights dedup command  \n",
      "Generating embeddings for:   Amazon DynamoDB now simplifies and lowers the cost of handling failed conditional writes \n",
      "Generating embeddings for:   Amazon S3 provides restore status of S3 Glacier objects using the S3 LIST API \n",
      "Generating embeddings for:   AWS Database Migration Service now provides more comprehensive premigration assessments \n",
      "Generating embeddings for:   Amazon CloudWatch now supports dashboard variables \n",
      "Generating embeddings for:   Amazon Simple Email Service now supports metric export \n",
      "Generating embeddings for:   AWS Amplify Hosting announces support for monorepo frameworks \n",
      "Generating embeddings for:   Amazon Athena now supports querying restored data in S3 Glacier \n",
      "Generating embeddings for:   AWS announces Amazon Aurora MySQL zero-ETL integration with Amazon Redshift (Public Preview) \n",
      "Generating embeddings for:   New ODBC driver now available for Amazon Athena \n",
      "Generating embeddings for:   Amazon Athena is now available in the AWS Middle East (UAE) Region \n",
      "Generating embeddings for:   Amazon Aurora Serverless v2 is now available in Asia Pacific (Melbourne) \n",
      "Generating embeddings for:   AWS Systems Manager Parameter Store increases API throughput limit \n",
      "Generating embeddings for:   Amazon CloudWatch now supports Cross-Account Service Quotas \n",
      "Generating embeddings for:   Amazon OpenSearch Service now lets you provision higher IOPS and throughput for gp3 volumes \n",
      "Generating embeddings for:   AWS Backup expands cross-account backup AWS Region coverage \n",
      "Generating embeddings for: New Solution â€“ Clickstream Analytics on AWS for Mobile and Web Applications\n",
      "Generating embeddings for:   Introducing the AWS .NET Distributed Cache Provider for DynamoDB  \n",
      "Generating embeddings for:   Announcing DynamoDB local version 2.0 \n",
      "Generating embeddings for:   AWS Lambda now detects and stops recursive loops in Lambda functions \n",
      "Generating embeddings for:   Amazon CloudFront announces support for 3072-bit RSA certificates \n",
      "Generating embeddings for:   Announcing DynamoDB local version 2.0 \n",
      "Generating embeddings for:   AWS DMS now supports Amazon Redshift Serverless as a target \n",
      "Generating embeddings for:   Amazon S3 Inventory can include ACLs as object metadata in inventory reports \n",
      "Generating embeddings for:   Amazon Location Service now supports publishing device position updates on EventBridge \n",
      "Generating embeddings for:   Amazon Location Service now supports API Keys for Maps, Places, and Routes \n",
      "Generating embeddings for:   Amazon Aurora supports PostgreSQL 15.3, 14.8, 13.11, 12.15, and 11.20 versions \n",
      "Generating embeddings for:  What's New with AWS?\n",
      "Printing sizes\n",
      "(32, 1536)\n",
      "(32, 1536)\n",
      "(32, 1536)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from functions.embeddings.context import generate_benchmark_embeddings, load_data\n",
    "from functions.embeddings.embed import generate_embedding\n",
    "from constants import SETTINGS\n",
    "\n",
    "\n",
    "def fetch_benchmark_embeddings():\n",
    "  benchmark_content = load_data(SETTINGS.rss_feed_file)\n",
    "\n",
    "  content_embeddings, title_embeddings, summary_embeddings = generate_benchmark_embeddings(benchmark_content)\n",
    "  \n",
    "\n",
    "  np_content_embeddings = np.array(content_embeddings)\n",
    "  np_title_embeddings = np.array(title_embeddings)\n",
    "  np_summary_embeddings = np.array(summary_embeddings)\n",
    "\n",
    "  print('Printing sizes')\n",
    "  print(np_content_embeddings.shape)\n",
    "  print(np_title_embeddings.shape)\n",
    "  print(np_summary_embeddings.shape)\n",
    "\n",
    "  return {\n",
    "    'content_embeddings': np_content_embeddings,\n",
    "    'title_embeddings': np_title_embeddings,\n",
    "    'summary_embeddings': np_summary_embeddings,\n",
    "  }\n",
    "\n",
    "\n",
    "data = fetch_benchmark_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving content embeddings\n",
      "Saving title embeddings\n",
      "Saving summary embeddings\n"
     ]
    }
   ],
   "source": [
    "from constants import SETTINGS\n",
    "def save_benchmark_embeddings(data):\n",
    "  fields = ['content', 'title', 'summary']\n",
    "\n",
    "  for field in fields:\n",
    "    embeddings = data[f'{field}_embeddings']\n",
    "    print(f'Saving {field} embeddings')\n",
    "    file_path = f'{SETTINGS.embeddings_output_dir}/benchmark_{field}.npy'\n",
    "    np.save(file_path, embeddings)\n",
    "\n",
    "save_benchmark_embeddings(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  content Clustering\n",
      "  Number of clusters: 5\n",
      "  Silhouette Score: 0.06386707535949496\n",
      "  \n",
      "\n",
      "  title Clustering\n",
      "  Number of clusters: 7\n",
      "  Silhouette Score: 0.046894887377231464\n",
      "  \n",
      "\n",
      "  summary Clustering\n",
      "  Number of clusters: 7\n",
      "  Silhouette Score: 0.07047154709467535\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "def create_clusters(field):\n",
    "\n",
    "  def cluster_embeddings(embeddings):\n",
    "    clustering = AffinityPropagation().fit(embeddings)\n",
    "    return clustering\n",
    "\n",
    "  embeddings = np.load(f'{SETTINGS.embeddings_output_dir}/benchmark_{field}.npy')\n",
    "  clustering = cluster_embeddings(embeddings)\n",
    "\n",
    "  print(f\"\"\"\n",
    "  {field} Clustering\n",
    "  Number of clusters: {len(clustering.cluster_centers_indices_)}\n",
    "  Silhouette Score: {metrics.silhouette_score(embeddings, clustering.labels_)}\n",
    "  \"\"\")\n",
    "\n",
    "for field in ['content', 'title', 'summary']:\n",
    "  create_clusters(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from constants import SETTINGS\n",
    "\n",
    "with open(SETTINGS.dot_products_file, 'r') as f:\n",
    "  file_data = f.read()\n",
    "  dot_product_data = json.loads(file_data)\n",
    "\n",
    "\n",
    "relevance_data = {}\n",
    "for article in dot_product_data:\n",
    "  title = article['title']\n",
    "  relevance_data[title] = {}\n",
    "  for field in ['content', 'title' , 'summary']:\n",
    "    dot_products = article[f'{field}_relevance']\n",
    "    max_dot_products = max(dot_products)\n",
    "    max_5_dot_products = sum(sorted(dot_products, reverse=True)[:5]) / 5\n",
    "    avg_dot_products = sum(dot_products) / len(dot_products)\n",
    "\n",
    "    \n",
    "    relevance_data[title][field] = {\n",
    "      'max': max_dot_products,\n",
    "      'max_5': max_5_dot_products,\n",
    "      'avg': avg_dot_products\n",
    "    }\n",
    "\n",
    "file_path = f'{SETTINGS.ranks_output_dir}/unranked.json'\n",
    "with open(file_path, 'w') as f:\n",
    "  f.write(json.dumps(relevance_data, indent=2))\n",
    "\n",
    "\n",
    "# Order by summary max relevance\n",
    "summary_relevance = sorted(relevance_data.items(), key=lambda x: x[1]['summary']['max'], reverse=True)\n",
    "summary_relevance = {k: v for k, v in summary_relevance}\n",
    "file_path = f'{SETTINGS.ranks_output_dir}/summary_max.json'\n",
    "with open(file_path, 'w') as f:\n",
    "  save_data = {index: { 'title': title, 'summary_max': data['summary']['max']} for index, (title, data) in enumerate(summary_relevance.items())}\n",
    "  f.write(json.dumps(save_data, indent=2))\n",
    "\n",
    "# Order by title max relevance\n",
    "title_relevance = sorted(relevance_data.items(), key=lambda x: x[1]['title']['max'], reverse=True)\n",
    "title_relevance = {k: v for k, v in title_relevance}\n",
    "file_path = f'{SETTINGS.ranks_output_dir}/title_max.json'\n",
    "with open(file_path, 'w') as f:\n",
    "  save_data = {index: { 'title': title, 'title_max': data['title']['max']} for index, (title, data) in enumerate(title_relevance.items())}\n",
    "  f.write(json.dumps(save_data, indent=2))\n",
    "\n",
    "# Order by content max relevance\n",
    "content_relevance = sorted(relevance_data.items(), key=lambda x: x[1]['content']['max'], reverse=True)\n",
    "content_relevance = {k: v for k, v in content_relevance}\n",
    "file_path = f'{SETTINGS.ranks_output_dir}/content_max.json'\n",
    "with open(file_path, 'w') as f:\n",
    "  save_data = {index: { 'title': title, 'content_max': data['content']['max']} for index, (title, data) in enumerate(content_relevance.items())}\n",
    "  f.write(json.dumps(save_data, indent=2))\n",
    "          \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fine-tune-article",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
